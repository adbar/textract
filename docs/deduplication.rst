Deduplication
=============

.. meta::
    :description lang=en:
        Duplicate content can harm data quality and efficiency. Trafilatura detects similar texts
        and segments using a LRU cache and locality sensitive hashing (LSH). 



The presence of duplicate content on the web can have detrimental effects on data quality and computational efficiency. To mitigate this issue, it is crucial to implement effective deduplication methods for web documents.

Trafilatura supports both detection of identical segments and near-duplicate removal. The former is coarse-grained while the latter uses a locality-sensitive hashing technique which allows for fine-grained detection of related parts or texts. The process begins with text preprocessing, followed by hashing to generate a unique digital fingerprint for each text snippet. Metrics are then applied to quantify the degree of similarity between texts.



Element and paragraph level
---------------------------


Extraction functions
^^^^^^^^^^^^^^^^^^^^


The functions ``extract()`` and ``bare_extraction`` include a parameter to allow for removal of duplicate segments. This option is not activated by default and can be set using two different methods:
- ``deduplicate = True``
- ``options.dedup = True`` (see ``settings.Extractor``)




Custom functions
^^^^^^^^^^^^^^^^

The ``duplicate_test()`` function checks for duplicate text content within an LXML element using a least recently used (LRU) cache mechanism. It evaluates whether the text content of an element has been encountered before and how many times, helping to identify and flag repetitive text based on specified criteria.

Parameters

    element (lxml.etree._Element): An LXML element whose text content is to be checked for duplicates.
    options (object): An object containing configuration options for the duplication check. The options object must include:
        min_duplcheck_size (int): The minimum length of text content to be considered for duplication checking.
        max_repetitions (int): The maximum allowed number of repetitions for the text content before it is considered a duplicate.


.. code-block:: python

    >>> from trafilatura.deduplication import duplicate_test


Document level
--------------

Content hashing
^^^^^^^^^^^^^^^

The `SimHash <https://en.wikipedia.org/wiki/SimHash>`_ method, also known as Charikar's hash, is used to detect near-duplicate content. It implements a `locality-sensitive hashing <https://en.wikipedia.org/wiki/Locality-sensitive_hashing>`_ approach, which uses a rolling hash and hamming distance comparisons. It offers a balance of speed and accuracy to find similar web texts.

By setting a similarity threshold, you can use SimHash to determine whether two pieces of content are near duplicates. The similarity method returns a value between 0 and 1, indicating the degree of similarity between the two texts.


.. code-block:: python

    >>> from trafilatura.deduplication import Simhash

    >>> first = Simhash("This is a text.")
    >>> second = Simhash("This is a test.")
    >>> second.similarity(first)
    0.84375


It is also possible to reuse an existing SimHash object by passing its hash value:


.. code-block:: python

    >>> first_copy = Simhash(existing_hash=first.hash)
    >>> first_copy.similarity(first)
    1.0




The ``content_fingerprint()`` function generates a simhash value for any string. It focuses on meaningful bits of the given content and allows for efficient comparison and identification of similar content.


.. code-block:: python

    >>> from trafilatura.deduplication import content_fingerprint




The ``generate_hash_filename()`` function takes a string as input and returns a file name-safe string generated by hashing the given content. This approach ensures that identical or nearly identical files receive the same or very similar file names, making it easy to identify and manage them.


.. code-block:: python

    # create a filename-safe string by hashing the given content
    >>> from trafilatura.deduplication import generate_hash_filename
    >>> generate_hash_filename("This is a text.")
    'qAgzZnskrcRgeftk'


.. note::
    The ``trafilatura.hashing`` submodule has been renamed ``trafilatura.deduplication`` in version 1.10.0.
